{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image-classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOhYz7Q7C_TV",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "  #@title Default title text\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorboardcolab import * \n",
        "from google.colab.patches import cv2_imshow\n",
        "# loading data\n",
        "\n",
        "# from tensorflow.examples.tutorials.mnist import input_data\n",
        "# mn = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
        "\n",
        "((train_data,train_labels),(eval_data,eval_labels)) = tf.keras.datasets.mnist.load_data()\n",
        "train_data = train_data/np.float32(255)\n",
        "train_labels = train_labels.astype(np.int32)\n",
        "X = tf.placeholder(\"float\")/np.float32(255)\n",
        "Y = tf.placeholder(\"int32\")\n",
        "x = np.array_split(train_data,len(train_data)/10000)\n",
        "y = np.array_split(train_labels,len(train_labels)/10000)\n",
        "#..................... making model ...................\n",
        "# input layer\n",
        "input_layer = tf.reshape(X,[-1, 28, 28, 1])\n",
        "\n",
        "# 1st convolution layer\n",
        "conv1 = tf.layers.conv2d(inputs=input_layer, filters=32, kernel_size=5, padding=\"same\", activation=tf.nn.relu)\n",
        "\n",
        "# 1st pooling layer\n",
        "pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=2, strides=2)\n",
        "\n",
        "# 2nd convolution layer\n",
        "conv2 = tf.layers.conv2d(inputs=pool1, filters=64, kernel_size=5, padding=\"same\", activation=tf.nn.relu)\n",
        "\n",
        "# 2nd pooling layer\n",
        "pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=2, strides=2)\n",
        "\n",
        "pool2_flat = tf.reshape(pool2,[-1, 7*7*64])\n",
        "\n",
        "# dense layer\n",
        "dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
        "\n",
        "# logit layer\n",
        "logit = tf.layers.dense(inputs=dense, units=10)\n",
        "\n",
        "# loss function\n",
        "loss = tf.losses.sparse_softmax_cross_entropy(labels=Y, logits=logit )\n",
        "\n",
        "# optimization\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
        "training = optimizer.minimize(loss)\n",
        "\n",
        "\n",
        "model = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "# tbc = TensorBoardColab() # To create a tensorboardcolab object it will automatically creat a link\n",
        "# writer = tbc.get_writer() # To create a FileWriter\n",
        "# writer.add_graph(tf.get_default_graph()) # add the graph \n",
        "# writer.flush()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    writer = tf.summary.FileWriter(\"./check3\", sess.graph)\n",
        "    sess.run(model)\n",
        "    for i in range(20):\n",
        "        print (\"hello\")\n",
        "        for ii in range(len(x)):\n",
        "            sess.run(training, feed_dict={X:x[ii], Y:y[ii]})\n",
        "    save_path = saver.save(sess, \"./check3/model.ckpt\")\n",
        "    writer.close()\n",
        "with tf.Session() as sess1:\n",
        "    saver.restore(sess1, save_path)\n",
        "    prediction = logit.eval(feed_dict={X: eval_data[0:5]})\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LrbnXeD2XdM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import skimage\n",
        "X = tf.placeholder(\"float\")\n",
        "softmax = tf.nn.softmax(X)\n",
        "#softmax = tf.exp(X) / tf.reduce_sum(tf.exp(X))\n",
        "# pred = tf.placeholder(\"float\")\n",
        "\n",
        "\n",
        "# l = tf.math.softmax(pred)\n",
        "# with tf.Session() as sess:\n",
        "#   out = l.eval(feed_dict={pred:prediction})\n",
        "w=4\n",
        "with tf.Session():\n",
        "  out = softmax.eval(feed_dict={X:prediction})\n",
        "print (np.argmax(out[w]))\n",
        "skimage.io.imshow(eval_data[w])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}